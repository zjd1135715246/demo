

[toc]

### jvm内存结构

```
jvm内存模型：
jvm内存模型可以按照线程是否私有分为两类，一类是所有线程共享的，一类是每个线程私有的
所有线程共享的区有：
堆区：
堆区是在jvm启动的时候创建，他主要存储的是每一个对象的引用和数组分配的内存，堆中的对象不用显示的释放，gc会帮我们释放并回收内存
方法区：
方法区也是在jvm启动时创建，它存储的是类的结构，还包含了像运行时常量池，字段和方法数据，构造函数的代码
运行时常量池：
运行时常量池就是类和接口的字节码文件里的常量在运行时的表现形式，它包含了在编译时就确定的常量，和必须在运行时解析的方法，运行时常量池在类或接口被jvm创建时才会被创建

线程私有：
pc寄存器：
因为jvm是支持多线程同时运行的，每个线程都会有自己的pc寄存器，任何时候一个线程只能运行一个方法的代码，如果方法不是native的，pc寄存器存的就是正在执行的jvm指令的地址，如果是native的，那么pc寄存器的值就是未定义的

jvm栈：
jvm里有一个栈，随着线程的创建而创建，jvm栈主要用来存储帧，用来管理帧的入栈和出栈。每个线程都有自己的帧，帧包含了本地变量数组和操作数栈和一个当前执行方法所在类在运行时常量池的引用

native栈：
native不是用java实现的，但jvm需要提供对它的支持

帧：
在线程运行的时候，每执行一个方法，就会创建一个帧，当这个方法执行完的时候，帧就会被销毁，不论这个方法是正常执行完毕还是抛异常结束。每个帧都会有自己的本地变量数组和操作数据栈，还有一个当前类在运行时常量池的引用，本地变量数组和操作数据栈的大小在编译时就被确定，他们的内存在方法被调用时分配。
在一个线程运行时，只会有一个帧在激活状态，这个帧称为当前帧，这个方法称为当前方法，这个类就叫当前类，在这个方法调用另一个方法时，就会创建另一个帧，而这个帧就会称为当前帧，当这个方法执行完后，他吧返回值返回给上一帧，上一帧被激活，当前帧被销毁，上一帧成为当前帧

本地变量数组：
每一帧都会有自己的本地变量数组，它的大小在编译时就会被确定，在帧创建后分配内存。本地变量数组用来存储当前方法的局部变量和上一个方法传进来的参数，本地变量数组是一个下标从0开始的一个数组，一个位置能存储一个变量，但是long和double类型的变量要占两个大小的位置。long和double的变量只能通过小的下标来寻址，但是可以通过大的下标去插入。
上一个方法传入的变量会从0开始存储，这里会分成两种情况，一种是类方法也就是静态方法，他传入的参数就直接从0开始存储如果是非静态方法，也就是成员方法的话，0位置存储的是成员的应用，也就是this，从1开始存储参数

操作数栈：
每一帧都有一个先进先出的栈，用来保存jvm正在执行的指令的操作数，这个栈的最大深度在编译时被确定的。
当帧被创建时，操作数栈是空的，jvm提供一些指令用来记载常量值，本地变量值到操作数栈上，另一些jvm指令用来使用这些数据执行操作，并把结果保存到操作数栈上
操作数栈也保存着将要调用方法需要的参数值和接收方法调用的返回值
long和double占用两个位置，其他类型数据占一个位置的深度。
```

### 垃圾回收

```
垃圾回收：
jvm栈，这里作用是管理帧的入栈和出栈，出栈时帧的数据就销毁了，所以不需要gc
native栈，和jvm栈作用类似，只是它管理的是本地方法，也不需要gc
pc寄存器也叫程序计数器，多线程的运行在jvm里是通过每个线程争取时间切片，当下一个线程争抢到时，这一线程就会处于等待状态，当下次这一线程被唤醒时，就是通过pc寄存器才能知道上次运行到哪里了。pc寄存器是jvm规范里唯一一个没有定义oom的区域，所以它也不需要gc

所以gc主要处理的是堆区

判断内存是否需要清理：
1.引用计数法：
  引用计数法就是对象每被引用一次，就给他的引用次数+1，当他的引用次数为0时，就表示这个对象可回收。但是他不能解决循环引用的情况
2.可达性算法：可达性算法就是以一系列叫做gcroot的对象为起点，引出它指向的下一节点，在以下一节点为起点，引出下一点，直到遍历完毕。形成一条引用链，这时当没有在引用链上的对象就会被回收。
	GC Root:类静态属性引用的对象、虚拟机栈的对象、常量引用对象都可以做gcroot
  

垃圾回收算法：
标记清除算法：标记清除算法就是在判断到哪些是需要清楚的内存后，直接清除掉这些数据，这样优点是速度快，缺点也很明显，这样清楚后很容易造成内存中连续的内存很小，如果需要一块连续的内存就会不够，但其实剩余的内存是够的
标记整理法：标记整理法就是在判断出那些是要清除的内存后，将要保留的移动到一边，需要清除的就在另一边，然后清除掉数据，这样的好处是又连续的内存了，缺点是需要多次移动数据，会造成消耗
复制算法：复制算法就是将内存里的数据占用的大小先复制出一块，再将不用清除的数据复制进去，再把原来的内存全部清除，这样做的最大缺点就是内存只有一半是可用的，另一半需要拿来做复制用。


堆区在jdk8之前，分为新生代，年老代和持久代。在jdk8后取消了持久代。持久代里放的是类的静态属性值。后面研究发现，98%的数据在第一次检测后就会被回收了。新生代和年老代的大小是1:2，新生代里又分成，Eden区，和s0，s1区，他们的大小是8:1:1。新生代发生的gc叫younggc，年老代发生的叫fullgc。每发生一次gc这些数据的年龄就会+1，一般发生gc的条件就是内存快满了或者自己区设置jvm参数调整。当Eden区快满时，就会发生一次younggc，会将保留下来的数据转移到s0区，然后清除Eden区，同时这些保留下来的数据年龄会+1，下一次当Eden区快满时，会把Eden区和s0区一起找到其中要留下的数据，把这些数据转移到s1区，然后清除Eden区和s0区，然后就重复循环这个过程，下次就是把s1和Eden区清除，放到s0区。但有的数据年龄到达15后，这个数据就会被存到年老代。而当年老代快满时，就会发生一次fullgc，就是会新生代年老代所有的内存。新生代的清除其实就是复制算法，年老代用的是标记清除算法。

```

### jvm命令

```
jps : java里类型linux下的ps命令，可以查看当前运行的java程序，-l 类型 ll命令
jstack： 查看java的栈空间信息
jinfo ： 查看jvm启动时参数，-flag 
	-XX:+PrintGCDetails  		(布尔类型，使用加减号。是否打印gc信息)
	-XX:MetaspaceSize=1024m  	(k,v类型，使用等号。调整元空间大小)
	-Xms等价于 -XX:InitialHeapSize
	-Xmx等价于 -XX:MaxHeapSize
	-Xss      -XX:ThreadStackSize(初始栈空间大小)
	-Xmn	  设置年轻代大小
	-XX:SurvivorRatio=8  设置eden区和survivor区的比例大小，设置的是eden区占比为8/10
	-XX:NewRatio=4		设置年老代和新生代的比例大小，设置的是年老代占比为4/5
	-XX:MaxTenuringThreshold  设置垃圾进入年老代的最大年龄，如果设置为0则不经过年轻代直接进入年老代，规定只能设置0-15
java -XX:+PrintFlagsInitial
java -XX:+PrintFlagsFinal
java -XX:+PrintCommandLineFlags
```

### oom

```
java.lang.StackOverflowError								栈内存溢出
java.lang.OutOfMemoryError:Java heap space					 
java.lang.OutOfMemoryError:GC overhead limit exceeded		  GC回收垃圾效率极低导致
java.lang.OutOfMemoryError:Direct buffer memory				 本地内存占满了
java.lang.OutOfMemoryError:unable to create new native thread 单进程创建的线程超过了系统规定的线程数（linux规定的单进程最大值为1024）
java.lang.OutOfMemoryError:Metaspace
```



### collection

```
集合：
java中集合分为两大类，分为collection和map
collection为最上层接口，下面分为三大类，分别是list、queue、set三大类接口实现，list下就是具体的实现类了，有arraylist，linkedlist和vector。queue接口有dequeue接口实现了它，和priorityqueue类。dequeue又有arrayqueue实现类。linkedlist也实现了quere接口。set接口下分别是hashset，linkedhashset和treeset
，list和set的主要区别在于list有序可重复，set无序不可重复
arraylist是由数组实现的，linkedlist是由链表实现的。数组和链表最大的区别在于数组是可以随机访问的，所以arraylist在查询上会更快。arraylist在查和改上速度更快，因为数组是一块连续的内存，可以随机访问，时间复杂度为o(1)，linkedlist是由链表实现的，它在查询上时间复杂度为o(n)。arraylist在增删上会慢一些，因为在每次增删时，数组内后续的元素都需要向前或先后移动，因为数组要保证它的内存连续。而linkedlist增删只需要找到位置即可插入。它的消耗只在于查询到插入位置，他两都是线程不安全的
vector是线程安全的，他是用数组实现的，但它的内部使用了大量的synchronize，它的效率会很低。所以现在一般不使用vector。它和arraylist的区别在于线程安全和扩容机制问题，arraylist扩容是原长度加上原长度向右位移1位后的长度，也就是1.5倍。vector扩容是是由它内部一个参数觉定的，但我们一般不会去配置，所以默认情况下就变为原来的两倍
priorityqueue不是按照插入顺序先进先出的，而是按照自己的排序规则先进先出的一个队列。实现普通队列使用arrayqueue，因为它的效率更高，而linkedlist会有额外的开销。arrayqueue也是由数组实现的。所以他在改查时更快，增删相对较慢。arrayqueue不能存null值。

hashset底层是使用hashmap实现的，他使用hashmap的key存值，所有的value都只向同一个对象，本身无序。查询速度很快。linkedhashset是由hashset和linkedlist组合的结构。保留了插入的o(1)的时间复杂度，又保留了插入的顺序。treeset是由红黑树实现的，实现了有序性，可以使用自然排序和自定义排序。但查询速度会变慢。
```

### Map

```
HashMap：
hashmap是存储key-value键值对的一种数据结构。他的底层是由数组+链表实现的。在jdk8后增加了红黑树来提高效率。hashmap里用key-value的形式保存数据，在jkd8之前叫做entry，在jdk8后叫做node，是map里的一个静态内部类。hashmap在执行插入的时，数组上的node都为null，在添加时，先计算出key的index值，然后将对象放到数组下标为index的位置上。
因为hash是有一定概率的重复的，所有如果两个不同的key的hash重复时，就会形成链表。在jdk8之前使用的是头插法，也就是将新值放入数组，原有的值压到链表里。在jdk8后就是使用的尾插法。在map里的数据达到一定量的时候，map就会扩容。map扩容有两个影响因素，一个是数组当前长度，另一个是负载因子。默认是0.75，也就是说在达到75%时，数组就会扩容，变为原来的两倍。并且会遍历原map，将原有的值重新hash，放入新map。重新hash的原因是hashmap计算index的公式是hashcode(key)&(length-1)，是和数组的长度有关的，在长度变化后，index也会改变。所以需要遍历重新hash。
改用尾插法的原因是在扩容后，原来链表里的数据也会重新hash，头插法可能会造成循环链表。这样在取值的时候就会造成无线循环了。在改为尾插法后，不管怎样都是保持原有的顺序放入链表，就可以解决这个问题了。
我们一般在重写hashcode方法时也需要重写equals方法。因为在向hashmap里存值的时候，我们是先计算hashcode的值，然后计算index，再添加到map里，如果这时有一个key不同但是hashcode相同的数据要存入时，如果没有重新equals方法，那就会把原有的值替换掉了。取得时候也一样，就不知道到底要取的是哪个值，所以从新hashcode方法一定要重写equals方法。因为equals方法比较的是两个对象的内存地址，不同对象的地址肯定是不同的。

HashMap和HashTable，concurrenthashmap
HashMap和HashTable区别在于HashMap的key，v都可以为null，而hashtable不行，hashtable在存null时会抛出空指针异常。hashmap会对null值做处理。hashmap是线程不安全的，hashtable是线程安全的，hashtable大量使用synchronize关键字。保证了线程的安全，但是效率会降低很多。这也就是hashtable不能存null值的原因。因为在多线程下hashtable里有null的话，就判断不了这里的null是还没存入还是存入了null值。扩容机制不同，hashmap扩容为原来的两倍，hashtable扩容为两倍+1。实现方式不同，hashmap继承的是abstractmap，hashtable继承的是dictionary。hashmap的迭代器是fail-fast的，hashtable的不是。
fail-fast：说的是迭代器机制(快速失败)，在java.util包下的集合类都使用的是这一机制。在遍历过程中，如果元素被修改。增加删除修改。那么就会抛出异常。迭代器在遍历时直接访问集合中的内容，并且会使用一个叫做modcount的值。如果在遍历的过程中元素发生改变，就会改变modcount的值。然后用modcount和exceptmodcount作比较。如果一致，就返回遍历。否则中止遍历。这种机制就是不能在多线程下并发使用的原因。
fail-safe：安全失败。java.util.concurrent包下的集合类使用这一机制。使用这一机制的集合在遍历时不会直接对原集合进行修改，而是先拷贝原集合，迭代器拿到的就是复制的集合。所以对原集合的改动迭代器感知不到。可以在多线程下使用，并发修改。
concurrenthashmap在1.7时是由segment数组和hashentry组成的。也是由数组加链表的形式组成。segment是concurrent维护的一个内部类，主要由hashentry组成。hashentry和hashmap差不多。区别在于hashentry的每个节点和下一节点都是由volatile修饰的。volatile的作用有，他可以实现不同线程对于变量操作的可见性，就是在一个线程修改了变量后，对于其他线程都是可见的。还有禁止指令重排。它在多线下效率高的原因是，他操作数据时不会每次都去做同步处理，它使用的是分段锁。一个segment的操作不会影响其他的segment。在put时，会先获取锁，如果获取失败，表示有其他线程在操作这个数据，这时会尝试自旋，如果达到最大次数就会用阻塞的方式获取锁，保证一定能获取到锁。get的话因为它的节点都是volatile修饰的，所以一定获取到的值一定是最新的，它的get效率很高，因为全程都不需要加锁。
在1.8后，不采用segment分段锁，改用CAS+synchronize来保证并发安全性。hashentry改为node。节点也用volatile修饰。并且引入了红黑树。它在put时大致的操作是
根据key计算出hashcode，判断是否需要初始化，为null说明可以写入，会使用CAS尝试写入，失败则自旋保证成功，在判断是否需要扩容，如果还不满足则使用synchronize写入数据，如果链表长度过长则转为红黑树。
```

### happen-before

```
是什么：JMM可以通过happen-before来保证跨线程下的内存可见性。如果一个操作happen-before另一个操作，那么第一个操作的结果对第二个操作可见。并且第一个操作先于第二个操作执行。但是在不影响最终结果的情况下，这里是允许重排序的。
具体规则：1.在单线程下的每个操作，happen-before于任意操作之后
		2.对于一个锁的解锁，happen-before于随后这个锁的加锁
		3.对于volatile的对象写，happen-before于对这个对象的读
		4.A happen-before 于B ，B happen-before C 那么 A happen-before C
		5.一个对象构造函数执结束happen-before于finalize方法的执行
```

### CAS

```
原理：CAS就是compare and swap比较并交换。它包含三个操作数。变量内存地址V，旧的预期值A，将要更新值B，只有当V和A相等时，才能更新成功。否则不执行更新。
缺点：1.不能解决ABA问题，就是内存最开始的值是A，有线程把值改为了B，另一个线程开始读到的也是A。在这个线程想要更新的时候，有线程又把值改回了A。这种漏洞就叫ABA问题。
	 2.如果CAS长时间获取不到锁一直在自旋，对cpu的消耗很大。
```



### 锁

```
从实现上来说可以分为互斥锁和自旋锁。加锁的目的是保证在任何时间都只有一个线程能访问到资源，避免因为多线程导致的共享资源错乱的问题。当资源已经有一个线程加锁后，其他线程加锁就会失败。互斥锁和自旋锁在失败后的处理方式不一样。互斥锁会在失败后释放cpu，给其他线程。而自旋锁失败后会自旋，进入忙等待状态。直到成功获取到锁。
互斥锁是一种独占锁，当一个线程加锁后，其他线程加锁会失败。其他线程释放cpu后，那他加锁的代码就会阻塞。互斥锁加锁失败进入等待状态的操作是由操作系统内核实现的，当加锁失败后，将线程置为等待状态，再等到资源释放后，将线程唤醒。这里会有两次上下文的切换。
自旋锁是通过cpu的CAS函数实现的，就是compare and swap，他不会主动产生上下文切换，所以消耗会小一些。一般加锁都是分为两步，先检查该资源是否已经加锁了，如果没有则执行第二部。将锁置为当前线程持有。CAS函数就是把这两条指令合并成一条硬件级指令，形成了原子指令。当发生线程竞争锁时，竞争失败的线程就会自旋，进入忙等待状态，直到他拿到锁，这里一般会使用cpu内置的pause函数实现。
从加锁后的效果上来说有读写锁。他由读锁和写锁组成。如果只读取共享资源则加读锁，如果要修改共享资源则加写锁。他的实现方式是，当写锁没有被线程持有时，多个读锁线程都可以持有共享资源，因为他们都不会修改资源。而当写锁持有到共享资源时，读线程获取读锁的操作会被阻塞，写线程获取写锁的操作也会被阻塞。他又分为读优先锁和写优先锁，读优先锁是当读线程获取到锁后，写线程获取写锁的操作会阻塞，其他读线程能获取读锁，知道读线程操作完后，写线程才能获取到锁。写优先锁则是当共享资源被读锁持有时，有写线程获取写锁会被阻塞，其他读线程获取读锁也会被阻塞，当读线程释放资源后，写线程会获取到锁，当写线程释放后其他读线程才能获取到锁。
乐观锁和悲观锁的区别在于他们对于操作资源时是否加锁，悲观锁就是心态是悲观的，认为每次操作时都可能会去修改资源，所以每次操作都会加锁，乐观锁是先修改完资源后，在验证这段时间内是否发生过冲突，如果没有其他线程修改资源，那么本次操作成功，如果有其他线程修改了资源，就放弃本次操作。也就是说其实乐观锁全程并没有加锁。
```

### volatile

```
因为现代计算机的cpu的运行速度很快，已经远快于内存的速度。所以为了更好地利用cpu的速度，计算机在cpu和内存之间加了一层高速缓存。每个cpu有自己的高速缓存，彼此不能直接访问别人的高速缓存，所有的共享资源只能通过主存来交互，所以会有可见性的问题。JMM描述了java程序中的各种变量的访问规则，每个线程有自己的工作内存，JMM规定了线程对于变量的操作必须要在自己的工作内存中完成，而不能直接读取主存的数据，并且不能访问其他线程的工作内存。synchronize做的是一个线程获取到资源后加锁，其他线程会阻塞，等到锁释放后拿到的就是最新数据了。而volatile做的是共享资源可见性，每个线程操作共享资源时会在自己的工做内存里建一个副本资源，而如果这个变量使用了volatile修饰，当有线程修改这个资源并把它写到主存时，其他线程的副本就会失效，会重新去主存取这个数据，这样取到的就是最新数据了。
当多个cpu操作到同一共享数据时，当需要会写到主存的时候，就会造成数据不一致的问题，这时候以谁的数据为准呢，为了解决数据一致性的问题，cpu会遵循缓存一致性的协议，如MESI协议。当cpu写数据时，发现这一数据是共享数据，就会发通知，通知其他cpu将变量的缓存设置为无效状态，当其他cpu使用这个变量时发现这个变量已经是无效状态了，就会去主存重新读取数据。
指令重排：指令重排说的是现代计算机处理器为了提高性能，会对代码的既定顺序进行指令重排序。一般重排序有三种。1.编译器在不改变单线程程序语义的情况下可以对语句进行重新排序。2.指令级的并行重排序，现代处理器才用了指令并行的技术来将多条指令重叠执行，如果不存在数据依赖性，处理器可以改变语句对应机器的指令执行顺序。3.内存系统的重排序，由于处理器使用缓存来读写缓存数据，这使得数据的写入看上去是乱序的。还有一个概念是as-if-serial，就是说不论怎么改变指令的执行顺序，都必须保证在单线程下执行的结果是不变的。
volatile会禁止指令重排，它是通过在特定位置插入内存屏障指令来实现禁止指令的重排序的，JMM会针对volatile对编译器指定特定的规则表，在执行读操作时，会在指令后插入两条内存屏障指令，在在执行写操作时会在指令前后各加一条内存屏障指令。
happen-before，说的是一个线程操作共享数据需要对另一个线程可见，那么这两个操作之间必须存在happens-before关系。
无法保证原子性：就是一次操作，要么完全成功，要么完全失败。所以说多线程下的类似累加这种读写操作volatile是无法保证安全的。
volatile和synchronize区别：
volatile可以作用于实例属性和类属性，synchronize还能作用于方法和代码块。volatile可以保证可见性，但无法保证原子性，synchronize是一种互斥锁机制，可以保证原子性。
```

### synchronize

```
实现原理：synchronize是java提供的一种原子性内置锁，这种使用者看不到的锁也成为监视器锁。再加上了synchronize的方法被编译后，会给这个方法的前后加上monitorenter和monitorexit字节码指令。他的依赖操作系统底层的互斥锁实现。他保证了原子性和内存数据的可见性。再执行monitorenter指令时会尝试获取对象锁，如果获取到了锁，锁的计数器会+1.此时其他竞争锁的线程会进入等待中。在执行monitorexit指令后，锁的计数器会-1，当为0时，则锁释放，处于等待的线程会继续竞争锁。
特点：
可重入性，synchronize在锁对象的时候会有一个计数器，会记录线程获取锁的次数，当执行完代码块后会－1，当为0的时候释放锁，这样可以避免一些死锁的情况。
不可中断性：在一个线程获取到锁以后，其它的线程都会处于阻塞状态，前一个不释放，后一个会一直阻塞，并且不能中断。lock就是可以中断的(trylock)
 
 synchronize的优化：现在的synchronize有时候并不是一个重量级锁了，锁的优化包括，自旋锁、自适应锁、锁消除、锁粗化、偏向锁、轻量级锁
 	自旋锁：自旋锁就是在获取锁失败后不会释放线程，而是进入一个忙等待状态，直到获取到锁。
 	自适应锁：自适应锁就是自适应的自旋锁，自旋时间不是固定的，而是由上一次锁的自旋时间决定。
 	锁消除：JVM检测到一些同步的代码块并没有处于争抢状态，不需要加锁，就会进行锁消除。
 	偏向锁：偏向锁说的是如果一个线程拿到锁，就会在对象头里记录偏向锁的线程id，当下次这个线程进入同步块的时候，就不需要进行CAS加锁和解锁了，偏向锁永远偏向第一个获取到锁的线程，如果没有其他线程来获取锁，就不会有加锁和解锁了。如果有其他线程来获取锁，持有偏向锁的线程就会释放偏向锁。
 	轻量级锁：JVM的对象头里有一些锁的标志位，当代码进入同步块时，会使用CAS来获取锁，如果成功会把对象头的标记为置为轻量级锁，失败则自旋获取锁。
 
 和lock的区别
 synchronize是关键字，lock是一个借口
 synchronize会自动释放锁，lock不会
 通过lock可以知道线程是否获取到锁，synchronize不能
 synchronize可以锁方法和代码块，lock只能锁代码块
 synchronize不能中断，lock可以中断

```

### ThreadLocal

```
threadlocal的作用主要是做数据隔离，填充的数据只属于当前线程。变量的数据相对于其他线程是隔离的。
使用：threadlocal在spring实现事务隔离时使用，来保证单线程操作数据库的连接是同一个数据库连接。
threadlocal由threadlocalmap组成，它的结构和hashmap类似，但没有了链表。也是由数组构成，entry继承了weakreference，也就是弱引用。在添加值时计算值的hash，因为没有了链表的存在，当发生hash冲突时，回向后顺移，直到当前位置没有数据，所以在取数据时如果冲突的情况较多，那么它的效率就会比较低。
```



### redis

```html
为什么用：因为现在很多情况下mysql已经满足不了我们的使用了，像首页的查询如果全走mysql很容易打穿数据库。所有需要走缓存，redis就是一个很好地缓存中间件。
为什么速度快：1.绝大部分的操作都是在内存里完成的，不需要走磁盘。2.数据结构简单，对数据的操作也简单。3.采用了单线程，不需要考虑多线程下的cpu切换而消耗资源，也不用进行锁操作导致的资源消耗。4.采用多路io复用模型，而不是阻塞io
有哪些数据结构：最基本的5种，string，list，set，zset，hash。还有如HyperLogLog（不精确的去重）、Pub/Sub（发布订阅）、BloomFilter、bitmap（位图）等
redis分布式锁：可以用redis的setnx来争抢锁，再给他一个过期时间（expire）防止忘记释放锁。
	如果在setnx后，expire之前系统挂了，锁一直不释放：可以通过set的指令，把setnx和expire当做一条指令执行。
找同一前缀的key:可以用keys指令找到同一前缀的key
	有什么问题：因为redis是单线程的。keys指令是以阻塞的方式获取的。
	代替：可以使用scan指令来找，它是无阻塞方式获取的，但是可能会获取到重复的key，需要自己再去一下重。
redis做异步队列：使用list做队列，用rpush放，lpop取，取不到说明没有了。取不到时需要适当sleep一下再重试。还可以使用blpop，它可以再取不到会阻塞，直到有消息
	一对多模式：可以使用Pub/Sub模式，实现一对多的消费。
		Pub/Sub模式缺点：消费者下线后，消息会消失
redis持久化：redis使用rdb和aof两种机制实现持久化，rdb是全量备份，aof是增量备份，在redis启动后，会进行一次全量备份，之后的操作会进行增量备份。如果重启会优先加载aof文件，aof文件不存在时，会加载rdb文件，都不存在会启动时报错。
	如果突然断电：这时会取决于aof设置的sync属性的值。如果需要非常精确，设置为每次操作都同步，但是在高性能下实现不了，所以一般是没s同步一次，最多也就是丢失1s的数据。
RDB怎么同步的：redis的rdb主要是fork和cow，fork指redis通过创建子进程来进行rdb操作。cow指copy on write。父子进程之间共享数据
AOF同步：aof指append-only file，它会记录每条修改的命令，以append-only的模式将命令记录到aof文件里，因为这个模式是只追加的，不存在磁盘寻址，所以很快
RDB和AOF优缺点：RDB优点：RDB备份redis是去生成子进程操作的，所以对redis的性能消耗很小，并且很适合做冷备，因为他会按照时间顺序生成多个备份文件。缺点是默认5分钟备份一次，如果发生故障那么就会丢失这5分钟的数据。AOF的优点：AOF备份的更全，默认是没s记录一次，那么最多也就是丢失1s的数据。而且AOF模式是叫做非常可读模式，很适合做灾难数据恢复的，就算发生的删库，我们只需要到aof文件里将最后的删库命令删除就好了。缺点是一样的数据，AOF文件回比RDB文件还大，而且开启AOF后，性能会比只开启RDB要低。
plpeline好处：pipeline可以将io次数缩减为一次，前提是命令之间没有因果关系
同步机制：redis可以使用主从同步，从从同步，同步时，主节点先进行一次bgsave，并同时将期间的修改记录到内存buffer，待完成后，将rdb文件给复制节点，复制节点将rdb文件加载到内存，这时会通知主节点将期间的变化再同步到复制节点就完成了。
缓存雪崩：如果有很多数据需要设置同一过期时间，如果设置的过于集中，这些key同时失效，redis会卡顿，并且这些数据如果访问量很大，还会造成数据库压力过大，这种情况可以给过期时间上加一个随机值，分散过期时间。
缓存穿透：缓存穿透指的是大量的查询一个redis里不存在的key，然后会去查询数据库，在数据库里也查不到，这样就会一直查询数据库，造成数据库压力过大。比如查一个id为-1的，就会一直查不到。这种情况我们可以查不到时给这个key在redis里设置成null，过期时间给个30s之类的。这样就可以保证没有这个key时也可以走redis，不会直接查询数据库了。过期时间设短一点可以防止正常情况也无法使用。还可以使用BloomFilter，他可以高效的判断key在数据库里是否存在，不存在就return掉。等存在了在去查库刷新redis
缓存击穿：缓存击穿说的是当有一个非常热点的key在不停的扛着并发，当它失效时，就会直接请求数据库，数据库肯定扛不住压力。这种情况我们可以设置这种非常热点的key永不过期，有更新时去更新这个key
redis怎么保证高可用：redis自己就支持集群模式，我们可以使用哨兵模式来保证高可用。哨兵模式一般采用一主二从，当master节点发生故障后，slave节点会自动选取新的master节点。
内存淘汰机制：redis的过期策略是定期删除+惰性删除。定期删除的意思就是redis会定期随机检查一部分设置有过期时间的key，将过期的删除。他不会去所有的key，因为数据太多，如果每次都全盘扫描的话性能消耗会非常大。惰性删除说的是，因为定期删除是有可能检查不掉有部分key的，当我们去查询时，去检查这个key是否失效了，失效了就删除。还有种情况就是定期删除+惰性删除都没有删除掉一些key。redis有自己的内存淘汰机制。allkeys-lru：尝试回收最少使用的key，volatile-lru：尝试回收最少使用的key，但仅限于在过期集合的key，allkeys-random：随机回收key，volatile-random:随机回收key，但仅限于在过期集合的key，volatile-ttl：回收在过期集合的key，并且优先回收ttl较短的key
数据库，redis双写一致性问题：只要使用了缓存，就避免不了双写一致性的问题，如果对数据准确性要求很高，可以把读请求和写请求串行化，放到一个内存队列中去，这样就可以保证不会出现不一致了，但是会造成并发性降低很多，成为系统的瓶颈。
Redis和Memcached的区别：redis支持更多的数据结构。redis原生支持集群模式，更方便扩展。mc不支持持久化和主从同步功能
bloomfilter：它可以用在缓存穿透和海量数据去重。它的原理是当一个元素需要放入集合中时，会先用n个散列函数计算出一个位数组的n个下标值，并将这些点的值置为1，这样当有元素进来时，判断这些点的值就行了，只要有0就说明一定不存在，全为1大概率存在。他快速的原因是牺牲了准确性。

集群：redis集群是把16384个槽分给集群中节点，每个节点通过gossip得知其他节点的信息，并在自身的clusterstate中记录了所有节点的信息和槽分配的信息。访问时会访问集群中的一个节点，如果命中槽则直接访问，如果未命中则返回槽的实际存在的节点，然后再去访问。
```



### 消息队列

```
为什么用:异步、削峰、解耦。随着业务的扩大，之前下单可能只是写入订单，现在增加了积分之类的东西后，如果全部在一个业务方法里完成，可能耗费的时间变得很长，这时候就可以吧业务拆分，利用队列来异步的完成业务。主流程只完成下单，其他的业务由消息队列异步的完成。这里如果是放在一个服务里也可以用线程池异步的完成，但是这样每次修改一个东西整个项目都需要重启，而且业务流程增多也需要重启整个项目，使用mq还可以达到解耦的效果，将业务分开，主流程完成后，只需要将消息放入mq，让其他服务去消费就行了。还有就是削峰，像做活动的时候，流量会增大很多，可能造成库压力太大，这时就可以用队列削峰，把请求放队列里，我们可以根据服务的情况自己设置每秒消费多少请求。
```



### mysql

```
mysql结构：客户端->连接器->分析器->优化器->查询器->引擎->得出结果
	    		  |(8.0后没有缓存)
	              缓存->得出结果
Innodb和MySIAM的区别：mysiam不支持事务，innodb支持。mysiam强调的是性能，所以执行速度更快。mysiam不支持外键，innodb支持。mysiam不支持行锁，innodb支持。innodb不支持fulltext类型的索引。
优化：1.Explain，使用explain可以查看sql的执行情况，这里的分析结果比较重要的是，type，possible_key,keys。type指本次查询结果，system(const的特列，表中只有一行)——>const(使用主键索引或唯一索引查询)——>eq-ref(在进行联合查询使用了唯一索引只查到一行)——>ref(使用了非唯一索引)——>range(查询条件使用到了索引，最后一个条件是一个范围条件)——>index(查询的字段是索引的一部分或使用了主键排序)——>all(全表扫描)。possible——key指可能会用到的索引，key指这次查询实际使用到了的索引。
	2.覆盖索引：如果查询的字段已经在索引中了，那么就不需要回表，直接能返回数据。覆盖索引能减少树的搜索次数
	3.联合索引：如果我们需要通过好几个字段去查询结果，我们可以给这几个字段创建一个联合索引，这样也可以不用回表。
	4.最佳左前缀原则：如果我们的查询条件有索引满足，可以把查询顺序和索引顺序保持一致，这样只需要改动顺序就能使用上索引（其实顺序不满足索引优化器也能优化到）
	5.索引下推：因为如果查询条件里有范围条件，那么范围条件之后的就无法使用索引。5.6之前如果有这种情况，只能先筛选索引条件里的列，其他的条件只能通过回表再去匹配，5.6之后可以在筛选时一并判断其他条件。减少了回表次数
	6.唯一索引和普通索引如何选择：这里关键是看change buffer。因为mysql在更新数据时，会先判断要更新的数据页是否在内存中，如果在内存就可以直接更新，如果不在，在不影响数据一致性的前提下，会先将操作记录在change buffer里，等到下次有访问这个数据时，将数据页加载到内存，再执行change buffer的操作。将changebuffer操作应用到数据页的操作叫做merge，merge除了发生在访问时，mysql自己设置的后台线程也会定期触发。对于唯一索引来说，所有的更新操作都要判断是否满足唯一原则。而要判断是否满足唯一需要先将数据加载到内存中再判断，这样做不如直接就把数据更新了，所有使用changebuffer只能使用在普通索引。因为changebuffer是先将操作缓存，等读的时候更新，如果我们的业务是需要更新完马上读，那么使用changebugffer是得不偿失的，所有changebuffer最好使用在写多读少的情况下。
	7.前缀索引：mysql还支持前缀索引，在有些字段比较长的时候，如果需要加索引，那么可以使用前缀索引，可以节省索引空间。索引选的越长，相同数据页能放下的索引越少。
	8.函数操作：如果在查询中使用了函数，那么索引也会失效。
	9.隐式转换：如果sql里的条件发生了隐式的转换，那么索引也会失效。比如字段是int类型，sql的条件是字符串类型的一个数字，就会发生隐式转换。
	10.隐式字符编码：还有可能发生隐式字符编码的转换，也会导致索引失效。
	
分解连接大查询:1.可以让缓存更高效，对于连接查询，一个表发生变化，那么本次查询的缓存会全部失效，分解后一个表的缓存失效其他表的缓存还能用
			2.减少锁的竞争
			3.在应用层拆分，更容易做到高性能和可伸缩
			4.拆分后使用in关键字对于id主键来说可能效率会更好

索引：数据结构：mysql的索引可以选择有B+树或者hash，默认是B+树。因为hash不适合访问搜索，如果查询条件有范围那么速度就会很慢，所以默认会选择B+树作为索引。
	 作用：可以提高查询时磁盘io的效率，还可以提高范围查询的效率。
页：mysql最基本的存储结构是页，所有的数据都存放在页里。各个数据页的内容可以组成一个双向链表，每个数据页可以组成一个单向链表。每个数据页都会生成一个页目录，当使用主键查询时，可以使用这个页目录，使用其他列查询就只能遍历这个单向链表。
回表：如果查询字段不包含在索引列里，查询时就会先通过条件查询出主键id，再通过id去主键索引树上找到对应的值。返回主键索引树搜索的过程就叫回表。
```

### 类加载机制

```
Java自带三个类加载器：BootStrap ClassLoader、Extention ClassLoader、AppClass loader
bootstrap classloader为最上层类加载器，主要加载最核心的类库，如jre_home/lib 下的jar包，也可以在启动jvm时指定 -Xbootclasspath参数来改变加载目录。
extention classloader为扩展的类加载器，用来加载jre_home/lib/ext目录下的jar和class
appclass loader是用来加载当前应用classpath下的所有类
jvm在启动时会先加载bootstrap classloader，再加载extclassloader ，最后加载appclassloader。每个类加载器都会有一个父加载器，如果创建时没有外部指定，那么就会把extclassloader指定为appclassloader的父加载器，把bootstrap指定为extclassloader的父加载器。我们在java代码里无法看到bootstrapclassloader的信息，因为bootstrapclassloader是用c++实现的，它是jvm的一部分。像基本类都是由它加载的。
双亲委托：类加载器加载class时，，会先查看这个类有没有被加载过，如果还没有被加载，不会先由自己去加载这个类，而是会去找父加载器，看看父加载器有没有加载过这个类，直到bootstrapcloasloader。bootstrapclassloader会去看自己的记载目录下有没有这个类，如果有就加载返回，没有则向下返回，直到自身去classpath下查找这个类。这种向上委托加载的方式就叫做双亲委派。
	作用：可以防止核心类库被修改。可以避免重复加载。
```

### 对象

```
内存结构：有对象头（包括markword和class指针），对象的实际数据，和对齐填充
		markword：markword存放自身运行时的数据，如hashcode，GC年龄，偏向锁id，锁标志状态，线程持有的锁等。markword被设计成一个不固定的大小，以便以更小的内存放更多的数据，它会根据对象的状态复用自己的空间。
		class指针：class指针指向元数据的地址
		对象实际数据：自身的全部成员变量
		对齐填充：不满8字节的会填充到8字节
		

引用类型：1.强引用：在代码里一般的赋值都是强引用，这种对象永远不会被GC回收
		2.软引用：软引用一般用softReference表示，只有用但不是必要的对象，在发生内存溢出前会回收这些对象。
		3.弱引用：弱引用一般用weakreference表示，弱引用对象在下次GC一定会被回收，不管内存是否足够
		4.虚引用：也叫幻影引用，是最弱的引用关系。
		
内存溢出和内存泄漏：内存溢出值创建的对象太多导致内存占满。内存泄漏指无用对象没有被回收
```

### 线程

```
线程和进程的区别：进程是程序的一次执行，是系统进行资源调度和分配的基本单位。它的作用是提高系统的并发性和资源的利用率。由于进程的创建和消耗切换等操作都会造成很大的系统消耗，所以进程不能创建的太多，线程就是比进程更小的能独立运行的单位。他是进程的一个实体，能减少程序并发执行时的时间空间开销。
状态：新建、运行、阻塞、等待、超时等待、中止
线程死锁：形成条件：1.一个线程获取资源后是独占资源的
				2.获取到资源后不释放
				3.在未使用完之前不能强行剥夺
				4.若干线程之间形成一种循环等待的关系
		形成原因：死锁的原因一般是获取资源顺序不当。一个线程获取到了资源A，又想去获取资源B，而B已经被一个线程获取到了，这个线程又想获取资源A，形成循环等待，而无法执行。
		
sleep():需要指定时间，该方法调用后会让当前线程进入阻塞状态，让其它所有的线程有机会执行，但是他不会释放锁标志位，其他线程任然拿不到共享资源
wait()：和sleep不同的是他会释放锁标志。
notify():1.8之前会随机唤醒一个处于等待队列中的线程，1.8改为唤醒处于队列头的线程
notifyall():唤醒所有处于等待队列的线程。
yield():他没有参数，不会释放释放锁标志。而且它做的只是使当前线程进入待执行状态，也就是说执行问完yield后他马上又执行了。还有和sleep不同的是他只会使和他同		优先级或者更优先级的线程有几会执行。
join():会使当前线程等待调用join()方法的线程执行完之后才能执行


线程池：
	核心参数：1.最大线程数maximumpoolsize
			2.核心线程数corepoolsize
			3.阻塞队列workqueue
			4.活跃时间keepalivetime
			5.拒绝策略
	流程：当我们提交任务时，线程池会根据corepoolsize的大小来创建若干个线程来执行任务，当corepoolsize满了后，创建的线程将会放入阻塞队列。当阻塞队列也满了后，将会创建max-corepoolsize个线程来执行任务，任务执行完后，等待keepalivetime时间后，线程被销毁。如果达到max，将会根据不同的拒绝策略处理。
```



### Spring

```
什么是spring：我们通常说的spring指spring framework，是spring模块的集合。spirng的核心模块包括，jdbc、jms、aop、aspectj、core、orm、web。test。
ioc：ioc是一种编程思想，既控制反转。它是把平常在程序中手动创建的对象交由spring去创建并管理，ioc容器是spring实现ioc的载体，ioc本质上就是一个map，map里保存着创建的bean。ioc就像一个工厂，在我们需要对象的时候就去工厂里拿，不需要关注对象是怎么创建出来的。ioc是一种思想，DI就是具体的实现。
aop：面向切面编程，它可以将那些不是业务逻辑，却为业务逻辑服务的代码封装起来，如日志服务，事务处理等。可以减少系统的重复代码，并有利于维护和拓展。spring aop是基于jdk代理实现的，因为jkd代理需要实现接口，如果是没有实现接口的对象，就无法使用jdk代理，这时就会使用cglib代理。会生成一个被代理对象的子类作为代理。
spring aop和aspectj aop的区别：springaop是运行时增强，aspectj是编译时增强。springaop是通过代理实现，aspectj基于字节码操作。
bean作用域：1.singleton唯一bean实例，spring的bean默认都是单例的
		  2.prototype，每次请求都创建一个新的bean
		  3.request，每次http请求会创建一个新的bean，该bean仅在当前httprequest内有效
		  4.session每次http请求会创建一个新的bean，该bean仅在当前session内有效
		  5.global-session，全局session作用域

bean线程安全问题:spring的bean都是单例的，但在多线程下不能保证对bean非静态属性操作的安全。
用到了哪些设计模式：1.工厂模式，beanfactory，applicationcontext等
				2.代理模式，aop
				3.单例模式，spring的bean默认都是单例的
				4.模板方法模式，jdbctemplate等
				
@component和@bean的区别：1.作用域不同，component作用于类，bean作用于对象
					  2.component是通过路径扫描装配到spring容器里的，bean通常是在标有component注解的类的方法上，他告诉spring这是一个类的实例。
					  
将一个类注册到spring的注解：@component、@controller、@service、@repository

spring的事务隔离级别:读未提交：不能避免 脏读、幻读、不可重复读
				  读已提交：不能避免 幻读、不可重复读
				  可重复读：不能避免 幻读            （mysql的默认级别）
				  串行化：  都能避免，但是效率会降低很多
spring的传播行为:1.required，以事务的方式运行，如果当前不存在事务，则新建事务，如果存在，则加入当前事务（默认级别）
			   2.required-news，以事务的方式运行，新建事务，如果当前存在事务，则把当前事务挂起（内外层事务互不影响）
			   3.nested，嵌套事务（内层事务不影响外层的，外层的会影响内层的）
			   4.mandatory，仅支持当前事务，当前没有事务则抛出异常
			   5.never，以非事务运行，如果存在事务则抛出异常
			   6.support，支持当前事务，当前没有事务则以非事务运行
			   7.not_support，以非事务运行，如果存在事务，则挂起事务

spring mvc工作流程：在接受到客户端的请求时，会先到dispatchservelet，由它找到handlermapping解析，找到handler后由handleradpter适配器找到handler处理器，处理器处理后会返回一个modelandview，再由视图解析器解析后返给dispatchservelet，再返回给客户端。
```



### dubbo

```
什么是RPC：rpc是 remote Procedure call远程过程调用，它相对的是本地过程调用，就是调用别的服务器上的接口
rpc和http：rpc和http并不是一个层级上的东西，http是传输协议，只是规定了传输的格式，rpc对比的是本地过程调用，它是用来不同服务器上服务之间的通信的，它可以使用http实现，也可以使用基于tcp的自定义的协议实现。

dubbo的组成：1.Prodiver，服务的提供者
		   2.customer，服务的消费者
		   3.monitor，服务监控中心
		   4.registry，服务注册中心
		   5.container，服务运行的容器
		   
dubbo启动过程：dubbo启动首先是服务提供者回向注册中心提交自己的地址以及能提供的服务，然后注册中心会把服务提供者的信息给消费者。之后可用通过负载均衡来选择一个提供者。如果提供者数据有变更的话注册中心会把变更后的信息给消费者。服务的提供者和消费者都会在内存中记录调用的次数和时间，会定时的将这些信息给监控中心。

服务暴露流程：服务的暴露会在spring ioc装载完成之后开始，会根据配置的参数组装一个URL，通过这个url的协议参数使用对应的协议来暴露，默认协议是dubbo协议，然后会把需要暴露的信息放到一个map里，供之后的远程调用查找，然后会把提供者的信息交给注册中心。

服务调用过程：调用时会根据负载均衡选择一个invoker发起远程过程调用，这时会记录此请求的id。服务端收到请求后会在map里找到对应的信息，然后找到具体的实现类，再把返回值返回，这个返回值会带上刚才的id，消费者收到返回值后会根据这个id唤醒对应的线程，一次远程调用就完成了。

SPI：service Prodiver interface，主要用于框架中，框架定义了一个接口，不同的使用者需要不同的实现，spi就是指定一个特殊的位置，javaspi指定在classpath/serives 下创建一个以接口全限定名的文件，文件里内存容是具体实现类的全限定名。这样就可以通过接口找到对应的实现类。
java spi的缺点：1.不能指定名字，在使用时很难准确的引用
			  2.只能通过遍历的方式去找到实现类
			  3.每次加载都需要全部加载，比较耗资源
所以dubbo使用自己实现的spi，通过给每个实现类命名，在使用时通过命名找到类全名来按需加载。	 

```

