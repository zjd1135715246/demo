

[toc]

### jvm内存模型

```
jvm内存模型：
jvm内存模型可以按照线程是否私有分为两类，一类是所有线程共享的，一类是每个线程私有的
所有线程共享的区有：
堆区：
堆区是在jvm启动的时候创建，他主要存储的是每一个对象的引用和数组分配的内存，堆中的对象不用显示的释放，gc会帮我们释放并回收内存
方法区：
方法区也是在jvm启动时创建，它存储的是类的结构，还包含了像运行时常量池，字段和方法数据，构造函数的代码
运行时常量池：
运行时常量池就是类和接口的字节码文件里的常量在运行时的表现形式，它包含了在编译时就确定的常量，和必须在运行时解析的方法，运行时常量池在类或接口被jvm创建时才会被创建

线程私有：
pc寄存器：
因为jvm是支持多线程同时运行的，每个线程都会有自己的pc寄存器，任何时候一个线程只能运行一个方法的代码，如果方法不是native的，pc寄存器存的就是正在执行的jvm指令的地址，如果是native的，那么pc寄存器的值就是未定义的

jvm栈：
jvm里有一个栈，随着线程的创建而创建，jvm栈主要用来存储帧，用来管理帧的入栈和出栈。每个线程都有自己的帧，帧包含了本地变量数组和操作数栈和一个当前执行方法所在类在运行时常量池的引用

native栈：
native不是用java实现的，但jvm需要提供对它的支持

帧：
在线程运行的时候，每执行一个方法，就会创建一个帧，当这个方法执行完的时候，帧就会被销毁，不论这个方法是正常执行完毕还是抛异常结束。每个帧都会有自己的本地变量数组和操作数据栈，还有一个当前类在运行时常量池的引用，本地变量数组和操作数据栈的大小在编译时就被确定，他们的内存在方法被调用时分配。
在一个线程运行时，只会有一个帧在激活状态，这个帧称为当前帧，这个方法称为当前方法，这个类就叫当前类，在这个方法调用另一个方法时，就会创建另一个帧，而这个帧就会称为当前帧，当这个方法执行完后，他吧返回值返回给上一帧，上一帧被激活，当前帧被销毁，上一帧成为当前帧

本地变量数组：
每一帧都会有自己的本地变量数组，它的大小在编译时就会被确定，在帧创建后分配内存。本地变量数组用来存储当前方法的局部变量和上一个方法传进来的参数，本地变量数组是一个下标从0开始的一个数组，一个位置能存储一个变量，但是long和double类型的变量要占两个大小的位置。long和double的变量只能通过小的下标来寻址，但是可以通过大的下标去插入。
上一个方法传入的变量会从0开始存储，这里会分成两种情况，一种是类方法也就是静态方法，他传入的参数就直接从0开始存储如果是非静态方法，也就是成员方法的话，0位置存储的是成员的应用，也就是this，从1开始存储参数

操作数栈：
每一帧都有一个先进先出的栈，用来保存jvm正在执行的指令的操作数，这个栈的最大深度在编译时被确定的。
当帧被创建时，操作数栈是空的，jvm提供一些指令用来记载常量值，本地变量值到操作数栈上，另一些jvm指令用来使用这些数据执行操作，并把结果保存到操作数栈上
操作数栈也保存着将要调用方法需要的参数值和接收方法调用的返回值
long和double占用两个位置，其他类型数据占一个位置的深度。
```

### 垃圾回收

```
垃圾回收：
jvm栈，这里作用是管理帧的入栈和出栈，出栈时帧的数据就销毁了，所以不需要gc
native栈，和jvm栈作用类似，只是它管理的是本地方法，也不需要gc
pc寄存器也叫程序计数器，多线程的运行在jvm里是通过每个线程争取时间切片，当下一个线程争抢到时，这一线程就会处于等待状态，当下次这一线程被唤醒时，就是通过pc寄存器才能知道上次运行到哪里了。pc寄存器是jvm规范里唯一一个没有定义oom的区域，所以它也不需要gc

所以gc主要处理的是堆区

判断内存是否需要清理：
1.引用计数法：
  引用计数法就是对象每被引用一次，就给他的引用次数+1，当他的引用次数为0时，就表示这个对象可回收。但是他不能解决循环引用的情况
2.可达性算法：可达性算法就是以一系列叫做gcroot的对象为起点，引出它指向的下一节点，在以下一节点为起点，引出下一点，直到遍历完毕。形成一条引用链，这时当没有在引用链上的对象就会被回收。
  

垃圾回收算法：
标记清除算法：标记清除算法就是在判断到哪些是需要清楚的内存后，直接清除掉这些数据，这样优点是速度快，缺点也很明显，这样清楚后很容易造成内存中连续的内存很小，如果需要一块连续的内存就会不够，但其实剩余的内存是够的
标记整理法：标记整理法就是在判断出那些是要清除的内存后，将要保留的移动到一边，需要清除的就在另一边，然后清除掉数据，这样的好处是又连续的内存了，缺点是需要多次移动数据，会造成消耗
复制算法：复制算法就是将内存里的数据占用的大小先复制出一块，再将不用清除的数据复制进去，再把原来的内存全部清除，这样做的最大缺点就是内存只有一半是可用的，另一半需要拿来做复制用。


堆区在jdk8之前，分为新生代，年老代和持久代。在jdk8后取消了持久代。持久代里放的是类的静态属性值。后面研究发现，98%的数据在第一次检测后就会被回收了。新生代和年老代的大小是1:2，新生代里又分成，Eden区，和s0，s1区，他们的大小是8:1:1。新生代发生的gc叫younggc，年老代发生的叫fullgc。每发生一次gc这些数据的年龄就会+1，一般发生gc的条件就是内存快满了或者自己区设置jvm参数调整。当Eden区快满时，就会发生一次younggc，会将保留下来的数据转移到s0区，然后清除Eden区，同时这些保留下来的数据年龄会+1，下一次当Eden区快满时，会把Eden区和s0区一起找到其中要留下的数据，把这些数据转移到s1区，然后清除Eden区和s0区，然后就重复循环这个过程，下次就是把s1和Eden区清除，放到s0区。但有的数据年龄到达15后，这个数据就会被存到年老代。而当年老代快满时，就会发生一次fullgc，就是会新生代年老代所有的内存。新生代的清除其实就是复制算法，年老代用的是标记清除算法。

```



### collection

```
集合：
java中集合分为两大类，分为collection和map
collection为最上层接口，下面分为三大类，分别是list、queue、set三大类接口实现，list下就是具体的实现类了，有arraylist，linkedlist和vector。queue接口有dequeue接口实现了它，和priorityqueue类。dequeue又有arrayqueue实现类。linkedlist也实现了quere接口。set接口下分别是hashset，linkedhashset和treeset
，list和set的主要区别在于list有序可重复，set无序不可重复
arraylist是由数组实现的，linkedlist是由链表实现的。数组和链表最大的区别在于数组是可以随机访问的，所以arraylist在查询上会更快。arraylist在查和改上速度更快，因为数组是一块连续的内存，可以随机访问，时间复杂度为o(1)，linkedlist是由链表实现的，它在查询上时间复杂度为o(n)。arraylist在增删上会慢一些，因为在每次增删时，数组内后续的元素都需要向前或先后移动，因为数组要保证它的内存连续。而linkedlist增删只需要找到位置即可插入。它的消耗只在于查询到插入位置，他两都是线程不安全的
vector是线程安全的，他是用数组实现的，但它的内部使用了大量的synchronize，它的效率会很低。所以现在一般不使用vector。它和arraylist的区别在于线程安全和扩容机制问题，arraylist扩容是原长度加上原长度向右位移1位后的长度，也就是1.5倍。vector扩容是是由它内部一个参数觉定的，但我们一般不会去配置，所以默认情况下就变为原来的两倍
priorityqueue不是按照插入顺序先进先出的，而是按照自己的排序规则先进先出的一个队列。实现普通队列使用arrayqueue，因为它的效率更高，而linkedlist会有额外的开销。arrayqueue也是由数组实现的。所以他在改查时更快，增删相对较慢。arrayqueue不能存null值。

hashset底层是使用hashmap实现的，他使用hashmap的key存值，所有的value都只向同一个对象，本身无序。查询速度很快。linkedhashset是由hashset和linkedlist组合的结构。保留了插入的o(1)的时间复杂度，又保留了插入的顺序。treeset是由红黑树实现的，实现了有序性，可以使用自然排序和自定义排序。但查询速度会变慢。
```

### Map

```
HashMap：
hashmap是存储key-value键值对的一种数据结构。他的底层是由数组+链表实现的。在jdk8后增加了红黑树来提高效率。hashmap里用key-value的形式保存数据，在jkd8之前叫做entry，在jdk8后叫做node，是map里的一个静态内部类。hashmap在执行插入的时，数组上的node都为null，在添加时，先计算出key的index值，然后将对象放到数组下标为index的位置上。
因为hash是有一定概率的重复的，所有如果两个不同的key的hash重复时，就会形成链表。在jdk8之前使用的是头插法，也就是将新值放入数组，原有的值压到链表里。在jdk8后就是使用的尾插法。在map里的数据达到一定量的时候，map就会扩容。map扩容有两个影响因素，一个是数组当前长度，另一个是负载因子。默认是0.75，也就是说在达到75%时，数组就会扩容，变为原来的两倍。并且会遍历原map，将原有的值重新hash，放入新map。重新hash的原因是hashmap计算index的公式是hashcode(key)&(length-1)，是和数组的长度有关的，在长度变化后，index也会改变。所以需要遍历重新hash。
改用尾插法的原因是在扩容后，原来链表里的数据也会重新hash，头插法可能会造成循环链表。这样在取值的时候就会造成无线循环了。在改为尾插法后，不管怎样都是保持原有的顺序放入链表，就可以解决这个问题了。
我们一般在重写hashcode方法时也需要重写equals方法。因为在向hashmap里存值的时候，我们是先计算hashcode的值，然后计算index，再添加到map里，如果这时有一个key不同但是hashcode相同的数据要存入时，如果没有重新equals方法，那就会把原有的值替换掉了。取得时候也一样，就不知道到底要取的是哪个值，所以从新hashcode方法一定要重写equals方法。因为equals方法比较的是两个对象的内存地址，不同对象的地址肯定是不同的。

HashMap和HashTable，concurrenthashmap
HashMap和HashTable区别在于HashMap的key，v都可以为null，而hashtable不行，hashtable在存null时会抛出空指针异常。hashmap会对null值做处理。hashmap是线程不安全的，hashtable是线程安全的，hashtable大量使用synchronize关键字。保证了线程的安全，但是效率会降低很多。这也就是hashtable不能存null值的原因。因为在多线程下hashtable里有null的话，就判断不了这里的null是还没存入还是存入了null值。扩容机制不同，hashmap扩容为原来的两倍，hashtable扩容为两倍+1。实现方式不同，hashmap继承的是abstractmap，hashtable继承的是dictionary。hashmap的迭代器是fail-fast的，hashtable的不是。
fail-fast说的是迭代器机制，在java.util包下的类都使用的是这一机制。在遍历过程中，如果元素被修改。增加删除修改。那么就会抛出异常。迭代器在遍历时直接访问集合中的内容，并且会使用一个叫做modcount的值。如果在遍历的过程中元素发生改变，就会改变modcount的值。然后用modcount和exceptmodcount作比较。如果一致，就返回遍历。否则中止遍历。这种机制就是不能在多线程下并发使用的原因。
concurrenthashmap在1.7时是由segment数组和hashentry组成的。也是由数组加链表的形式组成。segment是concurrent维护的一个内部类，主要由hashentry组成。hashentry和hashmap差不多。区别在于hashentry的每个节点和下一节点都是由volatile修饰的。volatile的作用有，他可以实现不同线程对于变量操作的可见性，就是在一个线程修改了变量后，对于其他线程都是可见的。还有禁止指令重排。它在多线下效率高的原因是，他操作数据时不会每次都去做同步处理，它使用的是分段锁。一个segment的操作不会影响其他的segment。在put时，会先获取锁，如果获取失败，表示有其他线程在操作这个数据，这时会尝试自旋，如果达到最大次数就会用阻塞的方式获取锁，保证一定能获取到锁。get的话因为它的节点都是volatile修饰的，所以一定获取到的值一定是最新的，它的get效率很高，因为全程都不需要加锁。
在1.8后，不采用segment分段锁，改用CAS+synchronize来保证并发安全性。hashentry改为node。节点也用volatile修饰。并且引入了红黑树。它在put时大致的操作是
根据key计算出hashcode，判断是否需要初始化，为null说明可以写入，会使用CAS尝试写入，失败则自旋保证成功，在判断是否需要扩容，如果还不满足则使用synchronize写入数据，如果链表长度过长则转为红黑树。
```

### 锁

```
从实现上来说可以分为互斥锁和自旋锁。加锁的目的是保证在任何时间都只有一个线程能访问到资源，避免因为多线程导致的共享资源错乱的问题。当资源已经有一个线程加锁后，其他线程加锁就会失败。互斥锁和自旋锁在失败后的处理方式不一样。互斥锁会在失败后释放cpu，给其他线程。而自旋锁失败后会自旋，进入忙等待状态。直到成功获取到锁。
互斥锁是一种独占锁，当一个线程加锁后，其他线程加锁会失败。其他线程释放cpu后，那他加锁的代码就会阻塞。互斥锁加锁失败进入等待状态的操作是由操作系统内核实现的，当加锁失败后，将线程置为等待状态，再等到资源释放后，将线程唤醒。这里会有两次上下文的切换。
自旋锁是通过cpu的CAS函数实现的，就是compare and swap，他不会主动产生上下文切换，所以消耗会小一些。一般加锁都是分为两步，先检查该资源是否已经加锁了，如果没有则执行第二部。将锁置为当前线程持有。CAS函数就是把这两条指令合并成一条硬件级指令，形成了原子指令。当发生线程竞争锁时，竞争失败的线程就会自旋，进入忙等待状态，直到他拿到锁，这里一般会使用cpu内置的pause函数实现。
从加锁后的效果上来说有读写锁。他由读锁和写锁组成。如果只读取共享资源则加读锁，如果要修改共享资源则加写锁。他的实现方式是，当写锁没有被线程持有时，多个读锁线程都可以持有共享资源，因为他们都不会修改资源。而当写锁持有到共享资源时，读线程获取读锁的操作会被阻塞，写线程获取写锁的操作也会被阻塞。他又分为读优先锁和写优先锁，读优先锁是当读线程获取到锁后，写线程获取写锁的操作会阻塞，其他读线程能获取读锁，知道读线程操作完后，写线程才能获取到锁。写优先锁则是当共享资源被读锁持有时，有写线程获取写锁会被阻塞，其他读线程获取读锁也会被阻塞，当读线程释放资源后，写线程会获取到锁，当写线程释放后其他读线程才能获取到锁。
乐观锁和悲观锁的区别在于他们对于操作资源时是否加锁，悲观锁就是心态是悲观的，认为每次操作时都可能会去修改资源，所以每次操作都会加锁，乐观锁是先修改完资源后，在验证这段时间内是否发生过冲突，如果没有其他线程修改资源，那么本次操作成功，如果有其他线程修改了资源，就放弃本次操作。也就是说其实乐观锁全程并没有加锁。
```

### volatile

```
因为现代计算机的cpu的运行速度很快，已经远快于内存的速度。所以为了更好地利用cpu的速度，计算机在cpu和内存之间加了一层高速缓存。每个cpu有自己的高速缓存，彼此不能直接访问别人的高速缓存，所有的共享资源只能通过主存来交互，所以会有可见性的问题。JMM描述了java程序中的各种变量的访问规则，每个线程有自己的工作内存，JMM规定了线程对于变量的操作必须要在自己的工作内存中完成，而不能直接读取主存的数据，并且不能访问其他线程的工作内存。synchronize做的是一个线程获取到资源后加锁，其他线程会阻塞，等到锁释放后拿到的就是最新数据了。而volatile做的是共享资源可见性，每个线程操作共享资源时会在自己的工做内存里建一个副本资源，而如果这个变量使用了volatile修饰，当有线程修改这个资源并把它写到主存时，其他线程的副本就会失效，会重新去主存取这个数据，这样取到的就是最新数据了。
当多个cpu操作到同一共享数据时，当需要会写到主存的时候，就会造成数据不一致的问题，这时候以谁的数据为准呢，为了解决数据一致性的问题，cpu会遵循缓存一致性的协议，如MESI协议。当cpu写数据时，发现这一数据是共享数据，就会发通知，通知其他cpu将变量的缓存设置为无效状态，当其他cpu使用这个变量时发现这个变量已经是无效状态了，就会去主存重新读取数据。
指令重排：指令重排说的是现代计算机处理器为了提高性能，会对代码的既定顺序进行指令重排序。一般重排序有三种。1.编译器在不改变单线程程序语义的情况下可以对语句进行重新排序。2.指令级的并行重排序，现代处理器才用了指令并行的技术来将多条指令重叠执行，如果不存在数据依赖性，处理器可以改变语句对应机器的指令执行顺序。3.内存系统的重排序，由于处理器使用缓存来读写缓存数据，这使得数据的写入看上去是乱序的。还有一个概念是as-if-serial，就是说不论怎么改变指令的执行顺序，都必须保证在单线程下执行的结果是不变的。
volatile会禁止指令重排，它是通过在特定位置插入内存屏障指令来实现禁止指令的重排序的，JMM会针对volatile对编译器指定特定的规则表，在执行读操作时，会在指令后插入两条内存屏障指令，在在执行写操作时会在指令前后各加一条内存屏障指令。
happens-before，说的是一个线程操作共享数据需要对另一个线程可见，那么这两个操作之间必须存在happens-before关系。
无法保证原子性：就是一次操作，要么完全成功，要么完全失败。所以说多线程下的类似累加这种读写操作volatile是无法保证安全的。
volatile和synchronize区别：
volatile可以作用于实例属性和类属性，synchronize还能作用于方法和代码块。volatile可以保证可见性，但无法保证原子性，synchronize是一种互斥锁机制，可以保证原子性。
```

### synchronize

```
特点：
可重入性，synchronize在锁对象的时候会有一个计数器，会记录线程获取锁的次数，当执行完代码块后会－1，当为0的时候释放锁，这样可以避免一些死锁的情况。
不可中断性：在一个线程获取到锁以后，其它的线程都会处于阻塞状态，前一个不释放，后一个会一直阻塞，并且不能中断。lock就是可以中断的(trylock)
 
 和lock的区别
 synchronize是关键字，lock是一个借口
 synchronize会自动释放锁，lock不会
 通过lock可以知道线程是否获取到锁，synchronize不能
 synchronize可以锁方法和代码块，lock只能锁代码块
 synchronize不能中断，lock可以中断

```

### ThreadLocal

```
threadlocal的作用主要是做数据隔离，填充的数据只属于当前线程。变量的数据相对于其他线程是隔离的。
使用：threadlocal在spring实现事务隔离时使用，来保证单线程操作数据库的连接是同一个数据库连接。
threadlocal由threadlocalmap组成，它的结构和hashmap类型，但没有了链表。也是由数组构成，entry继承了weakreference，也就是弱引用。在添加值时计算值的hash，因为没有了链表的存在，当发生hash冲突时，回向后顺移，直到当前位置没有数据，所以在取数据时如果冲突的情况较多，那么它的效率就会比较低。
```



### redis

```html
为什么用：因为现在很多情况下mysql已经满足不了我们的使用了，像首页的查询如果全走mysql很容易打穿数据库。所有需要走缓存，redis就是一个很好地缓存中间件。
有哪些数据结构：最基本的5种，string，list，set，zset，hash。还有如HyperLogLog、Pub/Sub、BloomFilter等
大量key同一时间过期（缓存雪崩）：如果有很多数据需要设置同一过期时间，如果设置的过于集中，redis会卡顿，并且这些数据如果访问量很大，还会造成数据库压力过大，所以需要在时间上加一个随机值，分散过期时间。
redis分布式锁：可以用redis的setnx来争抢锁，再给他一个过期时间（expire）防止忘记释放锁。
	如果在setnx后，expire之前系统挂了，锁一直不释放：可以通过set的指令，把setnx和expire当做一条指令执行。
找同一前缀的key:可以用keys指令找到同一前缀的key
	有什么问题：因为redis是单线程的。keys指令是以阻塞的方式获取的。
	代替：可以使用scan指令来找，它是无阻塞方式获取的，但是可能会获取到重复的key，需要自己再去一下重。
redis做异步队列：使用list做队列，用rpush放，lpop取，取不到说明没有了。取不到时需要适当sleep一下再重试。还可以使用blpop，它可以再取不到会阻塞，直到有消息
	一对多模式：可以使用Pub/Sub模式，实现一对多的消费。
		Pub/Sub模式缺点：消费者下线后，消息会消失
redis持久化：redis使用rdb和aof两种机制实现持久化，rdb是全量备份，aof是增量备份，在redis启动后，会进行一次全量备份，之后的操作会进行增量备份。如果重启会优先加载aof文件，aof文件不存在时，会加载rdb文件，都不存在会启动时报错。
	如果突然断电：这时会取决于aof设置的sync属性的值。如果需要非常精确，设置为每次操作都同步，但是在高性能下实现不了，所以一般是没s同步一次，最多也就是丢失1s的数据。
RDB怎么同步的：redis的rdb主要是fork客cow，fork指redis通过创建子进程来进行rdb操作。cow指copy on write。父子进程之间共享数据
plpeline好处：pipeline可以将io次数缩减为一次，前提是命令之间没有因果关系
同步机制：redis可以使用主从同步，从从同步，同步时，主节点先进行一次bgsave，并同时将期间的修改记录到内存buffer，待完成后，将rdb文件给复制节点，复制节点将rdb文件加载到内存，这时会通知主节点将期间的变化再同步到复制节点就完成了。
```





